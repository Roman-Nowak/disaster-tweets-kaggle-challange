{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OU-48EtsX7w"
      },
      "source": [
        "# BERT for disaster tweets classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShX9Mgu161IL"
      },
      "source": [
        "This notebook is meant to be run in Google collab on the gpu because of the computational cost of fine-tuning the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT6MaAMhtKgi"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSxVE7ezwzHr"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC64KzpWtkdQ",
        "outputId": "378e4c6b-70f8-4d90-9a60-94b526e80da7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.6 MB 15.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U \"tensorflow-text==2.9.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRAfHkLJtmdr",
        "outputId": "ae7ea931-bf12-4a18-ead2-8d968eb24660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.4 MB 13.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 75.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 238 kB 75.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 59.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 662 kB 74.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 80.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 19 kB/s \n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 56.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 63.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 67.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 439 kB 74.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 61.2 MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T5Wq1rUwojk",
        "outputId": "3c03dcc0-4e95-4a05-8ae8-62be7fbf390b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting textacy\n",
            "  Downloading textacy-0.12.0-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: spacy>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (3.4.3)\n",
            "Collecting pyphen>=0.10.0\n",
            "  Downloading pyphen-0.13.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 68.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.8/dist-packages (from textacy) (4.64.1)\n",
            "Collecting jellyfish>=0.8.0\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 73.9 MB/s \n",
            "\u001b[?25hCollecting cytoolz>=0.10.1\n",
            "  Downloading cytoolz-0.12.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 68.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (2.8.8)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (1.7.3)\n",
            "Requirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (5.2.0)\n",
            "Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.8/dist-packages (from textacy) (2.0.8)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.10.0->textacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.10.0->textacy) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.19.0->textacy) (3.1.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (1.10.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (1.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (57.4.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (3.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (21.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (2.11.3)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (8.1.5)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (1.0.3)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (0.10.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (3.0.10)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy>=3.0.0->textacy) (2.4.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy>=3.0.0->textacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy>=3.0.0->textacy) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=3.0.0->textacy) (4.4.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->textacy) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.0.0->textacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=3.0.0->textacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy>=3.0.0->textacy) (2.0.1)\n",
            "Building wheels for collected packages: jellyfish\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp38-cp38-linux_x86_64.whl size=70639 sha256=de62fa79b9f0cbc4c377134e9c2c9a495a29e3e79e22e281216349acfc3afc18\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/c7/3c/4c83132de76359e3a429fd09c08995945ca96c5290a41651d3\n",
            "Successfully built jellyfish\n",
            "Installing collected packages: pyphen, jellyfish, cytoolz, textacy\n",
            "Successfully installed cytoolz-0.12.0 jellyfish-0.9.0 pyphen-0.13.2 textacy-0.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install textacy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH-RWgScw1jN"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lrx2JOlatqiQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import html \n",
        "import re\n",
        "from textacy import preprocessing\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_models as tfm\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3YDjZvXt3Mv",
        "outputId": "0a8d0054-9a27-4222-e997-19e75251248f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bert_config.json',\n",
              " 'bert_model.ckpt.data-00000-of-00001',\n",
              " 'bert_model.ckpt.index',\n",
              " 'vocab.txt']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12\"\n",
        "tf.io.gfile.listdir(gs_folder_bert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qHhU9EF6UEF"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkXKsg2Q94Ez",
        "outputId": "3366b41b-8000-4a1d-b82d-2ccec9ee42de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jhDTxFOn95jd"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/disaster_tweets_data/train.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/disaster_tweets_data/test.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz5L9mOB_u8G"
      },
      "source": [
        "# Pre-process train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "upd5Nc2lJ63P"
      },
      "outputs": [],
      "source": [
        "# Replace missing values with an empty string.\n",
        "\n",
        "train[\"location\"] = train[\"location\"].fillna(\"\")\n",
        "train[\"keyword\"] = train[\"keyword\"].fillna(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UIqc1eU5_uh9"
      },
      "outputs": [],
      "source": [
        "# define noise removal function\n",
        "\n",
        "# define clean function\n",
        "# add / remove any line if necessary\n",
        "def clean(text):\n",
        "    # convert html escapes like &amp; by their plain-text representation\n",
        "    text = html.unescape(text) \n",
        "    \n",
        "    # subsitute tags like <tab> by spaces in the specified text or remove them\n",
        "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
        "    \n",
        "    # subsitute markdown URLs like [Some text](https://....)\n",
        "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
        "    \n",
        "    # subsitute text or code in brackets like [0]\n",
        "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
        "    \n",
        "    # subsitute standalone sequences of specials, matches &# but NOT #hashtag\n",
        "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
        "    \n",
        "    # subsitute standalone sequences of hyphens like --- or ==\n",
        "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
        "    \n",
        "    # sequences of white spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # remove stock market tickers like $GE\n",
        "    text = re.sub(r'\\$\\w*', '', text)  \n",
        "    \n",
        "    # remove old style retweet text \"RT\"\n",
        "    text = re.sub(r'RT[\\s]+', '', text)        \n",
        "    text = re.sub(r'DT[\\s]+', '', text)   \n",
        "    \n",
        "    # remove hashtags\n",
        "    text = re.sub(r'#', '', text)\n",
        "    \n",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Mznq_hKvB1UM"
      },
      "outputs": [],
      "source": [
        "# Create cleaning pipeline.\n",
        "preproc = preprocessing.make_pipeline(\n",
        "    \n",
        "    # join words split by a hyphen or line break\n",
        "    preprocessing.normalize.hyphenated_words,\n",
        "    \n",
        "    # subsitute fancy quatation marks with an ASCII equivalent\n",
        "    preprocessing.normalize.quotation_marks,\n",
        "    \n",
        "    # normalize unicode characters in text into canonical forms\n",
        "    preprocessing.normalize.unicode,\n",
        "    \n",
        "    # remove any accents character in text by replacing them with ASCII equivalents or removing them entirely\n",
        "    preprocessing.remove.accents,\n",
        "    \n",
        "    \n",
        "    # remove all email addresses in text \n",
        "    partial(preprocessing.replace.emails, repl= \"\"), # or _EMAIL_\n",
        "    \n",
        "    # remove all phone numbers in text \n",
        "    partial(preprocessing.replace.phone_numbers, repl=\"\"), # or _PhoneNumber_\n",
        "    \n",
        "    # remove all URLs in text \n",
        "    partial(preprocessing.replace.urls, repl= \"\"), # or _URL_\n",
        "    \n",
        "    # remove all (Twitter-style) user handles in text \n",
        "    partial(preprocessing.replace.user_handles, repl=\"\"), # or _HANDLE_\n",
        "    \n",
        "    # Replace all hashtags in text with repl.\n",
        "    #partial(preprocessing.replace.hashtags, repl=\"_HASTAG_\"),\n",
        "    \n",
        "    ### TEST ### Enable it only before generating tokens for word clouds\n",
        "    partial(preprocessing.replace.numbers, repl=\"\"),\n",
        "    \n",
        "    # remove HTML tags from text\n",
        "    preprocessing.remove.html_tags,\n",
        "    \n",
        "    # remove text within curly {}, square [], and/or round () brackets\n",
        "    preprocessing.remove.brackets,\n",
        "\n",
        "    # replace specific set of punctuation marks with whitespace\n",
        "    partial(preprocessing.remove.punctuation, only=[ \",\", \":\", \";\", \"/\", \" \",\"(\",\"@\"]),\n",
        "    \n",
        "    # Replace all currency symbols in text with repl\n",
        "    preprocessing.replace.currency_symbols,\n",
        "    \n",
        "    # replace all emoji and pictographs in text with repl.\n",
        "    preprocessing.replace.emojis,\n",
        "    \n",
        " )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "PKyu9MB9B7Yr",
        "outputId": "e175d153-abb4-4f18-d86d-2ca1b096d466"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-05e9fcce-0229-4c94-b600-8d8e20a1b315\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_c</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>keyword_c</th>\n",
              "      <th>clean_keyword</th>\n",
              "      <th>location_c</th>\n",
              "      <th>clean_location</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td></td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>destruction</td>\n",
              "      <td>destruction</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td></td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "      <td>The f&amp;@ing things I do for GISHWHES Just got s...</td>\n",
              "      <td>The f&amp; things I do for GISHWHES Just got soake...</td>\n",
              "      <td>deluge</td>\n",
              "      <td>deluge</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "      <td>@georgegalloway: @Galloway4Mayor: ÛÏThe CoL p...</td>\n",
              "      <td>UIThe CoL police can catch a pickpocket in L...</td>\n",
              "      <td>police</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td></td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>aftershock</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>trauma</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>Montgomery County MD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05e9fcce-0229-4c94-b600-8d8e20a1b315')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05e9fcce-0229-4c94-b600-8d8e20a1b315 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05e9fcce-0229-4c94-b600-8d8e20a1b315');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                          \n",
              "2227  3185       deluge                          \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                          \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \\\n",
              "2644  So you have a new weapon that can cause un-ima...       1   \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0   \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1   \n",
              "132   Aftershock back to school kick off was great. ...       0   \n",
              "6845  in response to trauma Children of Addicts deve...       0   \n",
              "\n",
              "                                                 text_c  \\\n",
              "2644  So you have a new weapon that can cause un-ima...   \n",
              "2227  The f&@ing things I do for GISHWHES Just got s...   \n",
              "5448  @georgegalloway: @Galloway4Mayor: ÛÏThe CoL p...   \n",
              "132   Aftershock back to school kick off was great. ...   \n",
              "6845  in response to trauma Children of Addicts deve...   \n",
              "\n",
              "                                             clean_text    keyword_c  \\\n",
              "2644  So you have a new weapon that can cause un-ima...  destruction   \n",
              "2227  The f& things I do for GISHWHES Just got soake...       deluge   \n",
              "5448   UIThe CoL police can catch a pickpocket in L...       police   \n",
              "132   Aftershock back to school kick off was great. ...   aftershock   \n",
              "6845  in response to trauma Children of Addicts deve...       trauma   \n",
              "\n",
              "     clean_keyword             location_c        clean_location  \n",
              "2644   destruction                                               \n",
              "2227        deluge                                               \n",
              "5448        police                     UK                    UK  \n",
              "132     aftershock                                               \n",
              "6845        trauma  Montgomery County, MD  Montgomery County MD  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['text_c'] = train['text'].apply(clean)\n",
        "train[\"clean_text\"] = train[\"text_c\"].apply(preproc)\n",
        "\n",
        "train['keyword_c'] = train['keyword'].apply(clean)\n",
        "train[\"clean_keyword\"] = train[\"keyword_c\"].apply(preproc)\n",
        "\n",
        "train['location_c'] = train['location'].apply(clean)\n",
        "train[\"clean_location\"] = train[\"location_c\"].apply(preproc)\n",
        "\n",
        "train.sample(5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hOsw0sH_Radi"
      },
      "outputs": [],
      "source": [
        "train['clean_joined_features'] = train[\"clean_text\"] + train[\"clean_keyword\"] + train[\"clean_location\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg8nWDjaCXar"
      },
      "source": [
        "## Formatting the data for BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FF06DxoICXJJ"
      },
      "outputs": [],
      "source": [
        "# BERT tokenizer.\n",
        "\n",
        "tokenizer = tfm.nlp.layers.FastWordpieceBertTokenizer(\n",
        "    vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n",
        "    lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "imnCiULaGoSG"
      },
      "outputs": [],
      "source": [
        "# BERT packer for formatting the inputs.\n",
        "\n",
        "max_seq_length = 128\n",
        "\n",
        "packer = tfm.nlp.layers.BertPackInputs(\n",
        "    seq_length=max_seq_length,\n",
        "    special_tokens_dict = tokenizer.get_special_tokens_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FSxiZssVHMUg"
      },
      "outputs": [],
      "source": [
        "# Class for pre-processing the text data\n",
        "\n",
        "class BertInputProcessor(tf.keras.layers.Layer):\n",
        "  def __init__(self, tokenizer, packer):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.packer = packer\n",
        "\n",
        "  def call(self, text):\n",
        "    text = self.tokenizer(text)\n",
        "\n",
        "    packed = self.packer([text])\n",
        "    return packed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BkoOzbWoP6AI"
      },
      "outputs": [],
      "source": [
        "bert_input_processor = BertInputProcessor(tokenizer, packer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BcLbOtRuQBQO"
      },
      "outputs": [],
      "source": [
        "# Example inputs for example prediction.\n",
        "example_inputs = bert_input_processor(list(train['clean_joined_features'])[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JGyzo0Ms7sVI"
      },
      "outputs": [],
      "source": [
        "inputs = bert_input_processor(list(train['clean_joined_features']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "p6FKe2__7fXm"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(inputs),\n",
        "                                                    list(train['target'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MqFu9exSBUp"
      },
      "source": [
        "# Fine-tuning BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PK72gz3SAry",
        "outputId": "6aac0278-e54d-420b-9471-c79311e8ff11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'attention_probs_dropout_prob': 0.1,\n",
              " 'hidden_act': 'gelu',\n",
              " 'hidden_dropout_prob': 0.1,\n",
              " 'hidden_size': 768,\n",
              " 'initializer_range': 0.02,\n",
              " 'intermediate_size': 3072,\n",
              " 'max_position_embeddings': 512,\n",
              " 'num_attention_heads': 12,\n",
              " 'num_hidden_layers': 12,\n",
              " 'type_vocab_size': 2,\n",
              " 'vocab_size': 30522}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "bert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\n",
        "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
        "config_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "mt43xQrUSRA8"
      },
      "outputs": [],
      "source": [
        "encoder_config = tfm.nlp.encoders.EncoderConfig({\n",
        "    'type':'bert',\n",
        "    'bert': config_dict\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdA0JJZgSTS0",
        "outputId": "22a4a396-8031-4782-cfa2-3dad506fbbb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<official.nlp.modeling.networks.bert_encoder.BertEncoder at 0x7f4d9c43f1f0>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_encoder = tfm.nlp.encoders.build_encoder(encoder_config)\n",
        "bert_encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FYwpPtu3Sh_I"
      },
      "outputs": [],
      "source": [
        "bert_classifier = tfm.nlp.models.BertClassifier(network=bert_encoder, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-d-M9L1Tewh",
        "outputId": "fc726426-7658-44c0-a60b-3c39f619b752"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.23425016, -0.3779763 ],\n",
              "       [-0.4125249 , -0.70295995],\n",
              "       [-0.38736963, -0.5819932 ],\n",
              "       [ 0.06214715, -0.91500294],\n",
              "       [-1.0778369 , -1.131032  ],\n",
              "       [-0.73366123, -1.0632837 ],\n",
              "       [-0.7215802 , -0.8319583 ],\n",
              "       [-0.6494328 , -0.9795061 ],\n",
              "       [-0.7649241 , -0.3588312 ],\n",
              "       [-0.17873794, -1.1142362 ]], dtype=float32)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example logit predictions.\n",
        "bert_classifier(\n",
        "    example_inputs, training=True).numpy()[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onwgVom25ky3"
      },
      "source": [
        "## BERT setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIo3axvE5Udy",
        "outputId": "72d22275-8ed4-4b77-c568-2299db286dde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4d9c164d30>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = tf.train.Checkpoint(encoder=bert_encoder)\n",
        "checkpoint.read(\n",
        "    os.path.join(gs_folder_bert, 'bert_model.ckpt')).assert_consumed()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Jq-ehFdJ6MVR"
      },
      "outputs": [],
      "source": [
        "# Set up epochs and steps\n",
        "epochs = 2\n",
        "batch_size = 32\n",
        "eval_batch_size = 32\n",
        "\n",
        "train_data_size = len(train['clean_joined_features'])\n",
        "steps_per_epoch = int(train_data_size / batch_size)\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "warmup_steps = int(0.1 * num_train_steps)\n",
        "initial_learning_rate=2e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "t1-Q8wHa6sIK"
      },
      "outputs": [],
      "source": [
        "linear_decay = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "    initial_learning_rate=initial_learning_rate,\n",
        "    end_learning_rate=0,\n",
        "    decay_steps=num_train_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QGYckXHe6vbH"
      },
      "outputs": [],
      "source": [
        "warmup_schedule = tfm.optimization.lr_schedule.LinearWarmup(\n",
        "    warmup_learning_rate = 0,\n",
        "    after_warmup_lr_sched = linear_decay,\n",
        "    warmup_steps = warmup_steps\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dL3CGDNU6yQ0"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.experimental.Adam(\n",
        "    learning_rate = warmup_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dFIHY6xf64vQ"
      },
      "outputs": [],
      "source": [
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "bert_classifier.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osg3-zlL66qC",
        "outputId": "d7037c46-072f-4190-d17e-f433f8ed30f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "238/238 [==============================] - 226s 800ms/step - loss: 0.4761 - accuracy: 0.7762\n",
            "Epoch 2/2\n",
            "238/238 [==============================] - 192s 805ms/step - loss: 0.3423 - accuracy: 0.8648\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d9c0db280>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_classifier.fit(\n",
        "      train_dataset.shuffle(len(train_dataset)).batch(batch_size),\n",
        "      batch_size=32,\n",
        "      epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVFrUO2vfQ11"
      },
      "source": [
        "# Get predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0O7L3tRGkHA"
      },
      "source": [
        "## Pre-processing the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ic4TlLl1fpw2"
      },
      "outputs": [],
      "source": [
        "test[\"location\"] = test[\"location\"].fillna(\"\")\n",
        "test[\"keyword\"] = test[\"keyword\"].fillna(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "oyPXVyI4fTYy",
        "outputId": "59eee184-edf1-44b3-f8a2-fda4d40089cb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-019e269d-2bcd-4f06-82a4-d0090ce198ea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>text_c</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>keyword_c</th>\n",
              "      <th>clean_keyword</th>\n",
              "      <th>location_c</th>\n",
              "      <th>clean_location</th>\n",
              "      <th>clean_joined_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td></td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>destruction</td>\n",
              "      <td>destruction</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td></td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "      <td>The f&amp;@ing things I do for GISHWHES Just got s...</td>\n",
              "      <td>The f&amp; things I do for GISHWHES Just got soake...</td>\n",
              "      <td>deluge</td>\n",
              "      <td>deluge</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>The f&amp; things I do for GISHWHES Just got soake...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "      <td>@georgegalloway: @Galloway4Mayor: ÛÏThe CoL p...</td>\n",
              "      <td>UIThe CoL police can catch a pickpocket in L...</td>\n",
              "      <td>police</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>UK</td>\n",
              "      <td>UIThe CoL police can catch a pickpocket in L...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td></td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>aftershock</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>trauma</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>Montgomery County MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-019e269d-2bcd-4f06-82a4-d0090ce198ea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-019e269d-2bcd-4f06-82a4-d0090ce198ea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-019e269d-2bcd-4f06-82a4-d0090ce198ea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                          \n",
              "2227  3185       deluge                          \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                          \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \\\n",
              "2644  So you have a new weapon that can cause un-ima...       1   \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0   \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1   \n",
              "132   Aftershock back to school kick off was great. ...       0   \n",
              "6845  in response to trauma Children of Addicts deve...       0   \n",
              "\n",
              "                                                 text_c  \\\n",
              "2644  So you have a new weapon that can cause un-ima...   \n",
              "2227  The f&@ing things I do for GISHWHES Just got s...   \n",
              "5448  @georgegalloway: @Galloway4Mayor: ÛÏThe CoL p...   \n",
              "132   Aftershock back to school kick off was great. ...   \n",
              "6845  in response to trauma Children of Addicts deve...   \n",
              "\n",
              "                                             clean_text    keyword_c  \\\n",
              "2644  So you have a new weapon that can cause un-ima...  destruction   \n",
              "2227  The f& things I do for GISHWHES Just got soake...       deluge   \n",
              "5448   UIThe CoL police can catch a pickpocket in L...       police   \n",
              "132   Aftershock back to school kick off was great. ...   aftershock   \n",
              "6845  in response to trauma Children of Addicts deve...       trauma   \n",
              "\n",
              "     clean_keyword             location_c        clean_location  \\\n",
              "2644   destruction                                                \n",
              "2227        deluge                                                \n",
              "5448        police                     UK                    UK   \n",
              "132     aftershock                                                \n",
              "6845        trauma  Montgomery County, MD  Montgomery County MD   \n",
              "\n",
              "                                  clean_joined_features  \n",
              "2644  So you have a new weapon that can cause un-ima...  \n",
              "2227  The f& things I do for GISHWHES Just got soake...  \n",
              "5448   UIThe CoL police can catch a pickpocket in L...  \n",
              "132   Aftershock back to school kick off was great. ...  \n",
              "6845  in response to trauma Children of Addicts deve...  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test['text_c'] = test['text'].apply(clean)\n",
        "test[\"clean_text\"] = test[\"text_c\"].apply(preproc)\n",
        "\n",
        "test['keyword_c'] = test['keyword'].apply(clean)\n",
        "test[\"clean_keyword\"] = test[\"keyword_c\"].apply(preproc)\n",
        "\n",
        "test['location_c'] = test['location'].apply(clean)\n",
        "test[\"clean_location\"] = test[\"location_c\"].apply(preproc)\n",
        "\n",
        "train.sample(5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JvE107N0fx5K"
      },
      "outputs": [],
      "source": [
        "test['clean_joined_features'] = test[\"clean_text\"] + test[\"clean_keyword\"] + test[\"clean_location\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3c14JSK5gHZ1"
      },
      "outputs": [],
      "source": [
        "test_inputs = bert_input_processor(list(test['clean_joined_features']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "ntNYJYzGgLzj"
      },
      "outputs": [],
      "source": [
        "test_dataset = tf.data.Dataset.from_tensor_slices(dict(test_inputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1jf9CT4GqO8"
      },
      "source": [
        "## Get predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxdn77iSeasP",
        "outputId": "868103a0-1697-4680-c95a-e40066a05764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 30s 289ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = bert_classifier.predict(test_dataset.batch(batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH2O4LLDguxE",
        "outputId": "79d2ee01-4fd0-4cb5-a7df-acd551bd8677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1.3821484 ,  0.9218454 ],\n",
              "       [-2.1851223 ,  1.8749597 ],\n",
              "       [-2.0271132 ,  1.7456344 ],\n",
              "       ...,\n",
              "       [-2.7556977 ,  2.787077  ],\n",
              "       [-1.1667815 ,  0.65156657],\n",
              "       [-0.81265354,  0.9463611 ]], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "s8RdJFtIgwdk"
      },
      "outputs": [],
      "source": [
        "def get_prediction_labels(predictions):\n",
        "  labels = []\n",
        "  for logit in predictions:\n",
        "    if logit[0] > logit[1]:\n",
        "      labels.append(0)\n",
        "    else:\n",
        "      labels.append(1)\n",
        "  return labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "27LmLNoQgxva"
      },
      "outputs": [],
      "source": [
        "labels = get_prediction_labels(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "e3LGSgUUhK3Q"
      },
      "outputs": [],
      "source": [
        "preds_df_bert = pd.DataFrame()\n",
        "preds_df_bert['id'] = test['id']\n",
        "preds_df_bert['target'] = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rcRaXbKLhSQd"
      },
      "outputs": [],
      "source": [
        "preds_df_bert.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2fZt7LlsNJT"
      },
      "source": [
        "# References\n",
        "* https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/classify_text_with_bert.ipynb\n",
        "* https://www.tensorflow.org/tfmodels/nlp/fine_tune_bert#train_the_model\n",
        "* https://www.kaggle.com/code/romannowak/nlp-with-disaster-tweets-cleaning-tf-idf-and-bert/edit"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 ('SDA_DASCI')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "0bb2324e7dcdba97b37be35a1f45ac0bb4ca5982753a2b22e8762c4337bc3e56"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
